
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "zata"
dynamic = ["version"]
description = "Template for Python projects."
readme = "README.md"
requires-python = ">=3.12,<3.13"
license = { file = "LICENSE.md" }
authors = [{ name = "Tho Nguyen", email = "contact@naiwaaa.simplelogin.com" }]
dependencies = [
  "tweepy>=4.14.0",
  "polars[numpy,plot,pydantic,style]>=1.15.0",
  #
  "torch>=2.5.1",
  "transformers>=4.46.3",
  "peft>=0.13.2",
  "unsloth>=2024.12.1",
  "trl>=0.12.1",
  "datasets>=3.1.0",
  #
  "wandb>=0.18.7",
  "pydantic>=2.10.2",
  "pydantic-settings>=2.6.1",
  "rich[jupyter]>=13.9.4",
  "typer-slim>=0.14.0",
  "gradio>=5.7.1",
  "gradio-client>=1.5.0",
]

[project.urls]
Homepage = "https://sr.ht/~naiwaaa/zata-agent"
Repository = "https://sr.ht/~naiwaaa/zata-agent"

[project.scripts]
zata = "zata.cli:app"

[tool.hatch.version]
path = "src/zata/__init__.py"

[tool.uv.sources]
torch = [{ index = "pytorch-cu124", marker = "platform_system != 'Darwin'" }]
torchvision = [{ index = "pytorch-cu124", marker = "platform_system != 'Darwin'" }]
torchaudio = [{ index = "pytorch-cu124", marker = "platform_system != 'Darwin'" }]

[[tool.uv.index]]
name = "pytorch-cu124"
url = "https://download.pytorch.org/whl/cu124"
explicit = true

[dependency-groups]
dev = ["pre-commit>=4.0.1", "ruff>=0.8.1"]
docs = ["pdoc>=15.0.0"]
notebooks = ["jupyterlab>=4.3.1", "jupytext>=1.16.4"]
testing = [
  "pytest>=8.3.3",
  "pytest-cov>=6.0.0",
  "pytest-mock>=3.14.0",
  "pytest-memray>=1.7.0",
  "pytest-pretty>=1.2.0",
  "pytest-clarity>=1.0.1",
  "pytest-randomly>=3.16.0",
  "pytest-instafail>=0.5.0",
  "pytest-benchmark>=5.1.0",
  "hypothesis>=6.121.1",
]
type-checking = ["mypy[faster-cache]>=1.13.0", "types-pillow>=10.2.0.20240822"]
all = [
  { include-group = 'dev' },
  { include-group = 'docs' },
  { include-group = 'notebooks' },
  { include-group = 'testing' },
  { include-group = 'type-checking' },
]

[tool.mypy]
mypy_path = "src"
python_version = "3.12"
exclude = [".cache/", ".venv/"]
# disallow dynamic typing
disallow_any_explicit = false
disallow_any_generics = true
# untyped definitions and calls
disallow_untyped_calls = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
# none and optional handling
implicit_optional = false
strict_optional = true
# configuring warnings
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_return_any = true
warn_unreachable = true
# miscellaneous strictness flags
allow_redefinition = false
enable_error_code = [
  "redundant-self",
  "redundant-expr",
  # "possibly-undefined",
  "truthy-bool",
  "truthy-iterable",
  "ignore-without-code",
  "unused-ignore",
  "narrowed-type-not-subtype",
]
implicit_reexport = false
strict_concatenate = true
strict_equality = true
strict = true
# configuring error messages
show_error_context = true
show_column_numbers = true
hide_error_codes = false
# incremental mode
cache_dir = ".cache/mypy"
# advanced options
plugins = ["numpy.typing.mypy_plugin", "pydantic.mypy"]
# miscellaneous
warn_unused_configs = false

[[tool.mypy.overrides]]
module = ["tweepy.*", "transformers.*", "gradio.*"]
ignore_missing_imports = true

[tool.pydantic-mypy]
init_forbid_extra = true
init_typed = true
warn_required_dynamic_aliases = true
warn_untyped_fields = true

[tool.pyright]
reportUnknownMemberType = "none"
reportCallIssue = "none"

[tool.pytest.ini_options]
addopts = [
  # general
  "--exitfirst",
  "-vv",
  "--failed-first",
  # reporting
  "--durations=5",
  "-ra",
  "--showlocals",
  # warnings
  "--strict-config",
  "--strict-markers",
  # collection
  # "--ignore-glob=**/fixtures/*",
  "--import-mode=importlib",
  "--doctest-modules",
  "--doctest-continue-on-failure",
  # pytest-cov
  "--cov",
  "--cov-report=term-missing:skip-covered",
  "--cov-config=pyproject.toml",
  # pytest-memray
  "--memray",
  "--most-allocations=5",
  # pytest-clarity
  "--diff-symbols",
  # pytest-instafail
  "--instafail",
  # pytest-benchmark
  "--benchmark-warmup=on",
  "--benchmark-columns=min,mean,stddev,outliers,rounds,iterations",
  "--benchmark-sort=mean",
  "--benchmark-disable-gc",
  "--benchmark-storage=file://./.cache/benchmarks",
  "--benchmark-disable",
  # hypothesis
  "--hypothesis-show-statistics",
  "--hypothesis-explain",
]
cache_dir = ".cache/pytest"
doctest_optionflags = "NUMBER IGNORE_EXCEPTION_DETAIL"
markers = ["slow: mark tests as slow"]
testpaths = ["src", "tests"]
verbosity_assertions = 2
xfail_strict = true

[tool.coverage.run]
source = ["src"]
branch = true
data_file = ".cache/coverage"
relative_files = true

[tool.coverage.report]
fail_under = 0
show_missing = true
skip_covered = true
exclude_lines = [
  "no cover",
  "if TYPE_CHECKING:",
  "raise NotImplementedError",
  "if __name__ == .__main__.:",
]
